{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2056c5f3",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e234b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('virusshare.csv', sep=',',skiprows=1, header=None).to_numpy()\n",
    "\n",
    "X = data[:,1:]\n",
    "Y = data[:,0]\n",
    "\n",
    "def testModel(model,modelName):\n",
    "    kf = KFold(n_splits=5)\n",
    "    acc_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_X, test_X = X[train_index], X[test_index]\n",
    "        train_Y, test_Y = Y[train_index], Y[test_index]\n",
    "        model.fit(train_X,train_Y)\n",
    "        pred_values = model.predict(test_X)\n",
    "        acc = accuracy_score(pred_values , test_Y)\n",
    "        f1 = f1_score(pred_values , test_Y)\n",
    "        acc_scores.append(acc)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    avg_acc_score = sum(acc_scores)/5\n",
    "    avg_f1_score = sum(f1_scores)/5\n",
    "\n",
    "    print('Method: '+modelName)\n",
    "    print('accuracy of each fold - {}'.format(acc_scores))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    print('f1 of each fold - {}'.format(f1_scores))\n",
    "    print('Avg f1 : {}'.format(avg_f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7067f3d",
   "metadata": {},
   "source": [
    "# Logistic Regression (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ba993ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Ridge logistic regression\n",
      "accuracy of each fold - [0.73825, 0.73475, 0.7515, 0.74925, 0.7655]\n",
      "Avg accuracy : 0.7478499999999999\n",
      "f1 of each fold - [0.7389678384442783, 0.7562600505398576, 0.7607125662012517, 0.7631641086186541, 0.7759197324414715]\n",
      "Avg f1 : 0.7590048592491028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "testModel(LogisticRegression(solver = \"liblinear\", penalty = \"l2\"),\"Ridge logistic regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10971ef1",
   "metadata": {},
   "source": [
    "# Logistic Regression (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cae0c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: LASSO logistic regression\n",
      "accuracy of each fold - [0.73825, 0.7345, 0.75225, 0.74625, 0.7655]\n",
      "Avg accuracy : 0.74735\n",
      "f1 of each fold - [0.7388376153654279, 0.7561983471074379, 0.7621790256779459, 0.7597633136094674, 0.7762404580152671]\n",
      "Avg f1 : 0.7586437519551092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "testModel(LogisticRegression(solver = \"liblinear\", penalty = \"l1\"),\"LASSO logistic regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383772bd",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8703f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: multilayer perceptron\n",
      "accuracy of each fold - [0.8145, 0.811, 0.8125, 0.81, 0.82425]\n",
      "Avg accuracy : 0.8144500000000001\n",
      "f1 of each fold - [0.8070722828913156, 0.8001057641459545, 0.7988197424892705, 0.8028022833419823, 0.814070351758794]\n",
      "Avg f1 : 0.8045740849254633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "testModel(MLPClassifier(solver='sgd', learning_rate = \"adaptive\", learning_rate_init = 0.1, alpha=1e-5,hidden_layer_sizes=(10, 2), random_state=1,max_iter=500),\"multilayer perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32366c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53cfbe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: SVM\n",
      "accuracy of each fold - [0.72825, 0.72975, 0.749, 0.742, 0.76425]\n",
      "Avg accuracy : 0.74265\n",
      "f1 of each fold - [0.7300720139061336, 0.7537024379129643, 0.7571359458151911, 0.755334281650071, 0.7746714456391874]\n",
      "Avg f1 : 0.7541832249847096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "testModel(LinearSVC(penalty = \"l1\", loss=\"squared_hinge\",dual=False, max_iter = 10000, tol = 0.001),\"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4a197",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e383e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: decision tree\n",
      "accuracy of each fold - [0.81975, 0.8125, 0.82275, 0.81975, 0.82325]\n",
      "Avg accuracy : 0.8196\n",
      "f1 of each fold - [0.8180671208680294, 0.8095479939055358, 0.8200050774308201, 0.8189806678383128, 0.823028785982478]\n",
      "Avg f1 : 0.8179259292050352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "testModel(DecisionTreeClassifier(random_state=0),\"decision tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44958529",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7612f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: random forest\n",
      "accuracy of each fold - [0.8435, 0.8415, 0.84675, 0.85375, 0.84625]\n",
      "Avg accuracy : 0.8463499999999999\n",
      "f1 of each fold - [0.8418393127842345, 0.8374358974358974, 0.8439011968423733, 0.8523100227215349, 0.8455162019593067]\n",
      "Avg f1 : 0.8442005263486694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "testModel(RandomForestClassifier(max_depth=300, random_state=0),\"random forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dc7a1",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c39a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Gaussian Naive Bayes\n",
      "accuracy of each fold - [0.58675, 0.57825, 0.58425, 0.61075, 0.58125]\n",
      "Avg accuracy : 0.58825\n",
      "f1 of each fold - [0.32777551850345665, 0.31283095723014254, 0.33824114604058897, 0.42609657206044965, 0.34132913881242627]\n",
      "Avg f1 : 0.34925466652941284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "testModel(GaussianNB(),\"Gaussian Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc98cf3",
   "metadata": {},
   "source": [
    "# k Nearest Neighbors (cosine distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36fee804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: kNN (cosine)\n",
      "accuracy of each fold - [0.829, 0.8265, 0.827, 0.83425, 0.8315]\n",
      "Avg accuracy : 0.82965\n",
      "f1 of each fold - [0.8298507462686568, 0.8231396534148827, 0.8231987736331119, 0.8336260978670011, 0.8325049701789264]\n",
      "Avg f1 : 0.8284640482725159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "testModel(KNeighborsClassifier(n_neighbors=5, metric=\"cosine\"),\"kNN (cosine)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f69cd5",
   "metadata": {},
   "source": [
    "# k Nearest Neighbors (Euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "105a324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: kNN (Euclidean)\n",
      "accuracy of each fold - [0.8305, 0.8225, 0.823, 0.827, 0.827]\n",
      "Avg accuracy : 0.826\n",
      "f1 of each fold - [0.8274809160305342, 0.820344129554656, 0.8212121212121212, 0.8287976249381495, 0.8288822947576656]\n",
      "Avg f1 : 0.8253434172986254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "testModel(KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\"),\"kNN (Euclidean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96067b22",
   "metadata": {},
   "source": [
    "# Ridge Logistic Regression + AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b76c314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: ridge + AdaBoost\n",
      "accuracy of each fold - [0.7365, 0.72725, 0.7345, 0.73925, 0.7345]\n",
      "Avg accuracy : 0.7344\n",
      "f1 of each fold - [0.7484486873508353, 0.7489067894131184, 0.7465393794749402, 0.7569331158238174, 0.7372587827808016]\n",
      "Avg f1 : 0.7476173509687026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ridge = LogisticRegression(solver = \"liblinear\",penalty = \"l2\")\n",
    "testModel(AdaBoostClassifier(estimator = ridge, n_estimators=30),\"ridge + AdaBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf0ebe",
   "metadata": {},
   "source": [
    "# Random Forest + AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6271ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: random forest + AdaBoost\n",
      "accuracy of each fold - [0.8545, 0.8495, 0.85325, 0.85, 0.859]\n",
      "Avg accuracy : 0.8532500000000001\n",
      "f1 of each fold - [0.8500772797527048, 0.845005149330587, 0.8484379034340304, 0.8474059003051881, 0.8578629032258064]\n",
      "Avg f1 : 0.8497578272096632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "testModel(AdaBoostClassifier(estimator = rf, n_estimators=10),\"random forest + AdaBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801c604",
   "metadata": {},
   "source": [
    "# FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e0f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [29 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"D:\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 144, in prepare_metadata_for_build_wheel\n",
      "      hook = backend.prepare_metadata_for_build_wheel\n",
      "  AttributeError: module 'ext' has no attribute 'prepare_metadata_for_build_wheel'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"D:\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 351, in <module>\n",
      "      main()\n",
      "    File \"D:\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 333, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"D:\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 148, in prepare_metadata_for_build_wheel\n",
      "      whl_basename = backend.build_wheel(metadata_directory, config_settings)\n",
      "    File \"C:\\Users\\34479\\AppData\\Local\\Temp\\pip-install-u3lftald\\datatable_9f538c168d4049f5969cad242dfc19d8\\ci\\ext.py\", line 573, in build_wheel\n",
      "      generate_build_info(flavor, strict=not is_source_distribution())\n",
      "    File \"C:\\Users\\34479\\AppData\\Local\\Temp\\pip-install-u3lftald\\datatable_9f538c168d4049f5969cad242dfc19d8\\ci\\ext.py\", line 467, in generate_build_info\n",
      "      git_hash = shell_cmd([\"git\", \"rev-parse\", \"HEAD\"], strict=strict)\n",
      "    File \"C:\\Users\\34479\\AppData\\Local\\Temp\\pip-install-u3lftald\\datatable_9f538c168d4049f5969cad242dfc19d8\\ci\\ext.py\", line 437, in shell_cmd\n",
      "      return subprocess.check_output(cmd, universal_newlines=True,\n",
      "    File \"D:\\anaconda3\\lib\\subprocess.py\", line 421, in check_output\n",
      "      return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "    File \"D:\\anaconda3\\lib\\subprocess.py\", line 503, in run\n",
      "      with Popen(*popenargs, **kwargs) as process:\n",
      "    File \"D:\\anaconda3\\lib\\subprocess.py\", line 971, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    File \"D:\\anaconda3\\lib\\subprocess.py\", line 1440, in _execute_child\n",
      "      hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "  FileNotFoundError: [WinError 2] 系统找不到指定的文件。\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datatable\n",
      "  Using cached datatable-1.0.0.tar.gz (1.1 MB)\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datatable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m pip install datatable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatatable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ftrl\n\u001b[0;32m      3\u001b[0m testModel(Ftrl(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFTRL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datatable'"
     ]
    }
   ],
   "source": [
    "! pip install datatable\n",
    "from datatable.models import Ftrl\n",
    "testModel(Ftrl(),\"FTRL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
